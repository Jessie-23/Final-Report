{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660a98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")) + '/lib/')\n",
    "\n",
    "from lib.blob_extraction import img_preprocess_mask, blob_detect, get_nodes_pos\n",
    "from lib.graph_generate import Delaunay_graph_generate\n",
    "from lib.voronoi_generate import cal_3d_Voronoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45014d",
   "metadata": {},
   "source": [
    "Parameter sweep for robust blob detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6917aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_IMAGE_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\")) + r\"\\data\\trans\\2_1_1_1\\frames_bw\\frame_0_0.png\"\n",
    "ZPARAM = dict(pool_neighbours=3, num_interp_points=50)\n",
    "\n",
    "PARAM_SETS = [\n",
    "    dict(ppm=dict(erosion=False, resize_x=300, resize_y=300, kernel_size=1,\n",
    "                  binary_threshold=50, circle_x_bias=0, circle_y_bias=0, circle_radius_bias=0),\n",
    "         mask_radius=None,   \n",
    "         blob=dict(minArea=5, blobColor=0, minCircularity=0.1, minConvexity=0.01, minInertiaRatio=0.01,\n",
    "                   thresholdStep=5, minDistBetweenBlobs=2.0, minRepeatability=2)),\n",
    "    dict(ppm=dict(erosion=False, resize_x=360, resize_y=360, kernel_size=1,\n",
    "                  binary_threshold=80, circle_x_bias=0, circle_y_bias=0, circle_radius_bias=0),\n",
    "         mask_radius=None,\n",
    "         blob=dict(minArea=7, blobColor=0, minCircularity=0.08, minConvexity=0.01, minInertiaRatio=0.01,\n",
    "                   thresholdStep=5, minDistBetweenBlobs=2.5, minRepeatability=2)),\n",
    "    dict(ppm=dict(erosion=False, resize_x=380, resize_y=380, kernel_size=1,\n",
    "                  binary_threshold=65, circle_x_bias=0, circle_y_bias=0, circle_radius_bias=0),\n",
    "         mask_radius=None,\n",
    "         blob=dict(minArea=6, blobColor=0, minCircularity=0.08, minConvexity=0.01, minInertiaRatio=0.01,\n",
    "                   thresholdStep=5, minDistBetweenBlobs=2.0, minRepeatability=2)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a926307",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e81bdf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract material label from directory name\n",
    "def material_key_from_dir(dir_name: str) -> str:\n",
    "    parts = dir_name.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        return f\"{parts[0]}_{parts[1]}\"\n",
    "    return dir_name\n",
    "\n",
    "#Load pose2 and pose6 values\n",
    "def load_targets_csv(csv_path: str):\n",
    "    if not os.path.exists(csv_path):\n",
    "        return {}\n",
    "    df = pd.read_csv(csv_path)\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    for k in [\"image_name\", \"pose_2\", \"pose_6\"]:\n",
    "        if k not in cols:\n",
    "            raise RuntimeError(f\"{csv_path} 缺少列: {k}\")\n",
    "    names = df[cols[\"image_name\"]].astype(str).apply(lambda s: Path(s).stem)\n",
    "    pose2 = pd.to_numeric(df[cols[\"pose_2\"]], errors=\"coerce\")\n",
    "    pose6 = pd.to_numeric(df[cols[\"pose_6\"]], errors=\"coerce\")\n",
    "    mapping = {}\n",
    "    for s, p2, p6 in zip(names, pose2, pose6):\n",
    "        mapping[s] = (float(p2) if pd.notna(p2) else np.nan,\n",
    "                      float(p6) if pd.notna(p6) else np.nan)\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ecdc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split graph list\n",
    "def stratified_split_by_class(data_list, y_list, test_ratio=0.25, seed=42):\n",
    "    rng = random.Random(seed)\n",
    "    per_class = defaultdict(list)\n",
    "    for idx, y in enumerate(y_list):\n",
    "        per_class[int(y)].append(idx)\n",
    "    train_idx, test_idx = [], []\n",
    "    for _, idxs in per_class.items():\n",
    "        rng.shuffle(idxs)\n",
    "        n = len(idxs)\n",
    "        n_test = max(1, int(round(n * test_ratio)))\n",
    "        test_idx.extend(idxs[:n_test])\n",
    "        train_idx.extend(idxs[n_test:])\n",
    "    return [data_list[i] for i in train_idx], [data_list[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e6376bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-estimate circular mask radius\n",
    "def _auto_mask_radius(h, w, scale=0.48):\n",
    "    return int(scale * min(h, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd83738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply image preprocessing\n",
    "def preprocess_and_detect_with_params(img_bgr, ppm, mask_radius, blob):\n",
    "    processed, white_mask, erosion = img_preprocess_mask(\n",
    "        img_bgr,\n",
    "        erosion=ppm[\"erosion\"],\n",
    "        resize_x=ppm[\"resize_x\"], resize_y=ppm[\"resize_y\"],\n",
    "        kernel_size=ppm[\"kernel_size\"],\n",
    "        binary_threshold=ppm[\"binary_threshold\"],\n",
    "        circle_x_bias=ppm[\"circle_x_bias\"],\n",
    "        circle_y_bias=ppm[\"circle_y_bias\"],\n",
    "        circle_radius_bias=ppm[\"circle_radius_bias\"]\n",
    "    )\n",
    "    if mask_radius is None:\n",
    "        mask_radius = _auto_mask_radius(processed.shape[0], processed.shape[1])\n",
    "\n",
    "    mask = np.zeros(processed.shape[:2], dtype=np.uint8)\n",
    "    center = (processed.shape[1] // 2, processed.shape[0] // 2)\n",
    "    cv2.circle(mask, center, mask_radius, 255, -1)\n",
    "    masked = cv2.bitwise_and(processed, processed, mask=mask)\n",
    "\n",
    "    kps = blob_detect(\n",
    "        masked,\n",
    "        minArea=blob[\"minArea\"], blobColor=blob[\"blobColor\"],\n",
    "        minCircularity=blob[\"minCircularity\"], minConvexity=blob[\"minConvexity\"],\n",
    "        minInertiaRatio=blob[\"minInertiaRatio\"], thresholdStep=blob[\"thresholdStep\"],\n",
    "        minDistBetweenBlobs=blob[\"minDistBetweenBlobs\"], minRepeatability=blob[\"minRepeatability\"]\n",
    "    )\n",
    "    nodes_pos = get_nodes_pos(kps)  # shape: [N, 2] (x,y)\n",
    "    return nodes_pos, masked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc3d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pins_with_sweep(img_bgr, min_pins=100, max_pins=400):\n",
    "    last_shape = None\n",
    "    for si, p in enumerate(PARAM_SETS):\n",
    "        nodes_pos, shp = preprocess_and_detect_with_params(img_bgr, p[\"ppm\"], p[\"mask_radius\"], p[\"blob\"])\n",
    "        last_shape = shp\n",
    "        n = nodes_pos.shape[0]\n",
    "        if min_pins <= n <= max_pins:\n",
    "            return nodes_pos, si, shp\n",
    "    return None, None, last_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "890a8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return layout label\n",
    "def classify_layout(n):\n",
    "    if 120 <= n <= 134:\n",
    "        return '127'\n",
    "    if 132 <= n <= 142:\n",
    "        return '137'\n",
    "    if 320 <= n <= 340:\n",
    "        return '331'\n",
    "    return 'generic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af28492",
   "metadata": {},
   "source": [
    "Auto template-based Voronoi transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6089ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatically select matching Voronoi transform template based on pin count.\n",
    "class TransformVoronoi_Auto:\n",
    "\n",
    "    def __init__(self, borderScale=1.1):\n",
    "        self.borderScale = float(borderScale)\n",
    "        self.T127 = self.T331 = self.T137 = None\n",
    "        try:\n",
    "            from lib.voronoi_generate import TransformVoronoi_127 as T127\n",
    "            self.T127 = T127\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            from lib.voronoi_generate import TransformVoronoi_331 as T331\n",
    "            self.T331 = T331\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            from lib.voronoi_generate import TransformVoronoi_137 as T137\n",
    "            self.T137 = T137\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_xy(xy):\n",
    "        xy = np.asarray(xy, dtype=np.float32)\n",
    "        c = xy.mean(axis=0, keepdims=True)\n",
    "        centered = xy - c\n",
    "        r = np.sqrt((centered**2).sum(axis=1)).mean()\n",
    "        if r < 1e-6:\n",
    "            r = 1.0\n",
    "        return centered / r\n",
    "\n",
    "    def _generic_voronoi(self, nodes_pos):\n",
    "        pts = np.asarray(nodes_pos, dtype=np.float32)\n",
    "        xmin, ymin = pts.min(axis=0)\n",
    "        xmax, ymax = pts.max(axis=0)\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        padx = (self.borderScale - 1.0) * w * 0.5\n",
    "        pady = (self.borderScale - 1.0) * h * 0.5\n",
    "        rect = (int(xmin - padx), int(ymin - pady), int(xmax + padx), int(ymax + pady))\n",
    "\n",
    "        subdiv = cv2.Subdiv2D(rect)\n",
    "        for (x, y) in pts:\n",
    "        \n",
    "            try:\n",
    "                subdiv.insert((float(x), float(y)))\n",
    "            except cv2.error:\n",
    "                pass\n",
    "\n",
    "        idx = list(range(len(pts)))\n",
    "        facets, centers = subdiv.getVoronoiFacetList(idx)\n",
    "\n",
    "        areas = np.zeros(len(pts), dtype=np.float32)\n",
    "        Cx = np.zeros(len(pts), dtype=np.float32)\n",
    "        Cy = np.zeros(len(pts), dtype=np.float32)\n",
    "\n",
    "        for i, (facet, c) in enumerate(zip(facets, centers)):\n",
    "            if facet is None or len(facet) == 0:\n",
    "                areas[i] = 0.0\n",
    "                Cx[i], Cy[i] = float(c[0]), float(c[1])\n",
    "                continue\n",
    "            poly = np.array(facet, dtype=np.float32)\n",
    "            areas[i] = float(cv2.contourArea(poly))\n",
    "            M = cv2.moments(poly)\n",
    "            if M[\"m00\"] != 0:\n",
    "                Cx[i] = float(M[\"m10\"] / M[\"m00\"])\n",
    "                Cy[i] = float(M[\"m01\"] / M[\"m00\"])\n",
    "            else:\n",
    "                Cx[i], Cy[i] = float(c[0]), float(c[1])\n",
    "\n",
    "        XY = self._normalize_xy(pts)  # Normalization\n",
    "        return areas, Cx, Cy, XY\n",
    "\n",
    "    def transform(self, nodes_pos):\n",
    "        n = nodes_pos.shape[0]\n",
    "        layout = classify_layout(n)\n",
    "        if layout == '127' and self.T127 is not None:\n",
    "            return self.T127(borderScale=self.borderScale).transform(nodes_pos)\n",
    "        if layout == '331' and self.T331 is not None:\n",
    "            return self.T331(borderScale=self.borderScale).transform(nodes_pos)\n",
    "        if layout == '137' and self.T137 is not None:\n",
    "            return self.T137(borderScale=self.borderScale).transform(nodes_pos)\n",
    "     \n",
    "        return self._generic_voronoi(nodes_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21259a05",
   "metadata": {},
   "source": [
    "Convert one image to graph + depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdcbb751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frame_to_graph_and_depth(img_bgr, transformer, Z_ref):\n",
    "    nodes_pos, set_idx, shp = detect_pins_with_sweep(img_bgr, min_pins=100, max_pins=400)\n",
    "    if nodes_pos is None:\n",
    "        return None, None, None, shp, set_idx, None\n",
    "\n",
    "    Axx, Cxx, Cyy, XY = transformer.transform(nodes_pos)\n",
    "    Xg, Yg, Z = cal_3d_Voronoi(Axx, Cxx, Cyy, **ZPARAM)\n",
    "    depth_scalar = float(np.mean(Z - Z_ref))\n",
    "\n",
    "    # Node\n",
    "    pair = np.asarray([XY[:, 0], XY[:, 1], Axx[:]]).T\n",
    "    x = torch.tensor(pair, dtype=torch.float)\n",
    "\n",
    "    # Edge\n",
    "    edge = torch.tensor(np.array(Delaunay_graph_generate(nodes_pos)).T, dtype=torch.long).contiguous()\n",
    "\n",
    "    return x, edge, depth_scalar, shp, set_idx, nodes_pos.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec52881b",
   "metadata": {},
   "source": [
    "Main dataset build function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be3dd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "def build_dataset(root_dir: str, train_dir: str, test_dir: str, seed: int = 42):\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    np.random.seed(seed); random.seed(seed)\n",
    "\n",
    "    root = Path(root_dir).resolve()\n",
    "    subdirs = [p for p in root.iterdir() if p.is_dir()]\n",
    "\n",
    "    material_keys = sorted({material_key_from_dir(p.name) for p in subdirs})\n",
    "    mat2idx = {mk: i for i, mk in enumerate(material_keys)}\n",
    "    num_classes = len(mat2idx)\n",
    "\n",
    "    transformer = TransformVoronoi_Auto(borderScale=1.1)\n",
    "\n",
    "    # Reference frame\n",
    "    if not os.path.exists(REF_IMAGE_PATH):\n",
    "        raise FileNotFoundError(f\"Reference frame not found: {REF_IMAGE_PATH}\")\n",
    "    ref_img = cv2.imread(REF_IMAGE_PATH)\n",
    "    ref_nodes, ref_set, ref_shape = detect_pins_with_sweep(ref_img, min_pins=100, max_pins=400)\n",
    "    if ref_nodes is None:\n",
    "        raise RuntimeError(\"Failed to detect valid pins in the reference frame\")\n",
    "    A_ref, Cx_ref, Cy_ref, XY_ref = transformer.transform(ref_nodes)\n",
    "    Xg_ref, Yg_ref, Z_ref = cal_3d_Voronoi(A_ref, Cx_ref, Cy_ref, **ZPARAM)\n",
    "    tip_num_ref = int(ref_nodes.shape[0])\n",
    "\n",
    "    # -Generation\n",
    "    data_list, y_list = [], []\n",
    "    pin_fail, used_set_hist = 0, [0]*len(PARAM_SETS)\n",
    "    last_shape = ref_shape\n",
    "    total_png = 0\n",
    "    pin_hist = defaultdict(int)\n",
    "    t0 = time.time()\n",
    "\n",
    "    for mat_dir in subdirs:\n",
    "        mk = material_key_from_dir(mat_dir.name)\n",
    "        y_idx = mat2idx[mk]\n",
    "\n",
    "        frames_dir = mat_dir / \"frames_bw\"\n",
    "        csv_path = mat_dir / \"targets.csv\"\n",
    "        '''if not frames_dir.exists():\n",
    "            print(f\"[WARN] 跳过 {mat_dir}: 无 frames_bw/\")\n",
    "            continue'''\n",
    "\n",
    "        labels = load_targets_csv(str(csv_path))\n",
    "        pngs = sorted(frames_dir.glob(\"*.png\"))\n",
    "        for img_path in pngs:\n",
    "            total_png += 1\n",
    "            stem = img_path.stem\n",
    "            p2, p6 = labels.get(stem, (np.nan, np.nan))\n",
    "\n",
    "            img = cv2.imread(str(img_path))\n",
    "            x, edge, depth_scalar, shp, set_idx, n_pins = frame_to_graph_and_depth(img, transformer, Z_ref)\n",
    "            last_shape = shp\n",
    "\n",
    "            if x is None:\n",
    "                pin_fail += 1\n",
    "                continue\n",
    "\n",
    "            used_set_hist[set_idx] += 1\n",
    "            pin_hist[int(n_pins)] += 1\n",
    "\n",
    "            t = torch.tensor([p2, p6, depth_scalar, float(y_idx)], dtype=torch.float)\n",
    "            y = torch.tensor(y_idx, dtype=torch.long)\n",
    "            data_list.append(Data(x=x, edge_index=edge, t=t, y=y))\n",
    "            y_list.append(y_idx)\n",
    "\n",
    "    # Save\n",
    "    train_val, test = stratified_split_by_class(data_list, y_list, test_ratio=0.25, seed=seed)\n",
    "\n",
    "    torch.save(train_val, str(Path(train_dir) / \"Train_val_data_list.pt\"))\n",
    "    torch.save(test,     str(Path(test_dir)  / \"Test_data_list.pt\"))\n",
    "    with open(Path(train_dir) / \"material_id_to_idx.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"material_id_to_idx\": {k: int(v) for k, v in mat2idx.items()},\n",
    "            \"num_classes\": int(num_classes),\n",
    "            \"tip_num_ref\": int(tip_num_ref),\n",
    "            \"ref_image_path\": REF_IMAGE_PATH,\n",
    "            \"z_params\": ZPARAM,\n",
    "            \"param_sets\": PARAM_SETS,\n",
    "            \"pin_hist\": {str(k): int(v) for k, v in sorted(pin_hist.items())}\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(\"\\nVoronoi Graph Dataset Loading Complete!!!\")\n",
    "    print(\"Example processed image shape:\", last_shape)\n",
    "    print(f\"Materials (classes): {num_classes}\")\n",
    "    print(f\"Images scanned: {total_png} | Graphs built: {len(data_list)}\")\n",
    "    print(f\"Train/Val: {len(train_val)} | Test: {len(test)}\")\n",
    "    print(f\"Pin extract fail: {pin_fail} | Used param sets: \" +\n",
    "          \", \".join([f\"S{i}:{c}\" for i,c in enumerate(used_set_hist)]))\n",
    "    print(\"Pin count histogram:\", dict(sorted(pin_hist.items())))\n",
    "    print(f\"Time cost: {dt:.2f}s | Speed: {(len(data_list)/dt) if dt>0 else 0:.2f} graphs/s\")\n",
    "\n",
    "    return train_val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "089c6394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Voronoi Graph Dataset Loading Complete!!!\n",
      "Example processed image shape: (300, 300)\n",
      "Materials (classes): 50\n",
      "Images scanned: 25251 | Graphs built: 24539\n",
      "Train/Val: 18414 | Test: 6125\n",
      "Pin extract fail: 712 | Used param sets: S0:16145, S1:8013, S2:381\n",
      "Pin count histogram: {100: 280, 101: 296, 102: 324, 103: 340, 104: 365, 105: 398, 106: 409, 107: 422, 108: 447, 109: 472, 110: 467, 111: 471, 112: 472, 113: 491, 114: 462, 115: 489, 116: 466, 117: 451, 118: 418, 119: 418, 120: 452, 121: 410, 122: 404, 123: 438, 124: 425, 125: 406, 126: 423, 127: 466, 128: 456, 129: 465, 130: 487, 131: 484, 132: 528, 133: 512, 134: 477, 135: 505, 136: 469, 137: 454, 138: 419, 139: 382, 140: 387, 141: 359, 142: 343, 143: 326, 144: 321, 145: 296, 146: 293, 147: 253, 148: 262, 149: 237, 150: 244, 151: 204, 152: 234, 153: 193, 154: 226, 155: 188, 156: 194, 157: 178, 158: 186, 159: 171, 160: 151, 161: 166, 162: 155, 163: 151, 164: 119, 165: 111, 166: 102, 167: 116, 168: 102, 169: 87, 170: 88, 171: 86, 172: 65, 173: 70, 174: 59, 175: 52, 176: 50, 177: 46, 178: 43, 179: 25, 180: 24, 181: 26, 182: 19, 183: 23, 184: 3, 185: 10, 186: 9, 187: 7, 188: 11, 189: 2, 190: 7, 191: 9, 192: 4, 193: 3, 194: 1, 195: 3, 196: 1, 197: 1, 199: 2, 200: 3, 201: 1, 206: 1, 207: 1, 208: 1, 211: 2, 214: 1, 215: 1, 221: 1, 222: 1, 228: 1, 231: 1}\n",
      "Time cost: 1253.50s | Speed: 19.58 graphs/s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    root_dir  = r\"..\\data\\trans\"   \n",
    "    train_dir = r\"..\\result\\train\"\n",
    "    test_dir  = r\"..\\result\\test\"\n",
    "    build_dataset(root_dir, train_dir, test_dir, seed=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tac-VGNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
